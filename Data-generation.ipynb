{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Data generation notebook\n",
    "\n",
    "Processing and generating data files for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_frames = {\n",
    "    'confirmed':  pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'),\n",
    "    'deaths': pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'),\n",
    "    'recovered': pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Remove cruises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    \n",
    "    df = df[df['Country/Region'] != 'Diamond Princess']\n",
    "    df = df[df['Country/Region'] != 'MS Zaandam']\n",
    "    \n",
    "    data_frames[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Rename countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    \n",
    "    df = df.replace(\"Cote d'Ivoire\", 'Ivory Coast')\n",
    "    df = df.replace(\"Cabo Verde\", 'Cape Verde')\n",
    "    df = df.replace(\"Congo (Brazzaville)\", 'Congo')\n",
    "    df = df.replace(\"Congo (Kinshasa)\", 'Democratic Republic of the Congo')\n",
    "    df = df.replace(\"Czechia\", 'Czech Republic')\n",
    "    df = df.replace(\"Holy See\", 'Vatican City')\n",
    "    df = df.replace(\"Korea, South\", 'South Korea')\n",
    "    df = df.replace(\"Taiwan*\", 'Taiwan')\n",
    "    df = df.replace(\"US\", 'United States')\n",
    "    df = df.replace(\"West Bank and Gaza\", 'State of Palestine')\n",
    "    df = df.replace(\"Burma\", 'Myanmar')\n",
    "    \n",
    "    data_frames[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Separate 'countries' such as Greenland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    \n",
    "    regions = ['Greenland', 'French Guiana', 'Falkland Islands (Malvinas)', 'New Caledonia']\n",
    "    \n",
    "    for region in regions:\n",
    "        df.loc[df['Province/State'] == region, 'Country/Region'] = region\n",
    "        \n",
    "    data_frames[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Group by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    df = df.drop(columns='Province/State')\n",
    "    \n",
    "    # Compute average of Lat and Long\n",
    "    agg_dict = {'Lat': 'mean',\n",
    "                'Long': 'mean'}\n",
    "    \n",
    "    # Sum the rest of the columns\n",
    "    for column in df.columns[3:]:\n",
    "        agg_dict[column] = 'sum'\n",
    "    \n",
    "    data_frames[key] = df.groupby('Country/Region').agg(agg_dict).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Reformat dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    dates = [x.strftime(\"%Y-%m-%d\") for x in pd.to_datetime(df.columns[3:])]\n",
    "    df.columns = list(df.columns[:3]) + dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Add world population column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "population_df = pd.read_csv('generated/population.csv')\n",
    "\n",
    "for key in data_frames.keys():\n",
    "    df = data_frames[key]\n",
    "    \n",
    "    df = df.merge(population_df, how='left', left_on='Country/Region', right_on='name')\n",
    "    df = df.drop(columns='name')\n",
    "    \n",
    "    # Reorder columns\n",
    "    df = df[['Country/Region', 'population'] + list(df.columns[1:-1])]\n",
    "    df = df.copy()\n",
    "    \n",
    "    data_frames[key] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Add sick dataset (confirmed - recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "confirmed = data_frames['confirmed']\n",
    "recovered = data_frames['recovered']\n",
    "# Check that the countries are in the same order\n",
    "assert((confirmed.loc[:, 'Country/Region'] != recovered.loc[:, 'Country/Region']).sum() == 0)\n",
    "\n",
    "sick = confirmed.copy()\n",
    "sick.loc[:, sick.columns[4:]] = confirmed.loc[:, sick.columns[4:]] - recovered.loc[:, sick.columns[4:]]\n",
    "data_frames['sick'] = sick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add daily dataset (number of confirmed cases for each day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = data_frames['confirmed'].copy()\n",
    "\n",
    "days = daily.loc[:, daily.columns[5:]]\n",
    "shifted_days = daily.loc[:, daily.columns[4:-1]]\n",
    "shifted_days.columns = days.columns\n",
    "\n",
    "daily.loc[:, daily.columns[5:]] = days - shifted_days\n",
    "data_frames['daily'] = daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R0 computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>population</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>2020-01-22</th>\n",
       "      <th>2020-01-23</th>\n",
       "      <th>2020-01-24</th>\n",
       "      <th>2020-01-25</th>\n",
       "      <th>2020-01-26</th>\n",
       "      <th>2020-01-27</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-04-20</th>\n",
       "      <th>2020-04-21</th>\n",
       "      <th>2020-04-22</th>\n",
       "      <th>2020-04-23</th>\n",
       "      <th>2020-04-24</th>\n",
       "      <th>2020-04-25</th>\n",
       "      <th>2020-04-26</th>\n",
       "      <th>2020-04-27</th>\n",
       "      <th>2020-04-28</th>\n",
       "      <th>2020-04-29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38041754</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2880917</td>\n",
       "      <td>41.153300</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>43053054</td>\n",
       "      <td>28.033900</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>77142</td>\n",
       "      <td>42.506300</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>31825295</td>\n",
       "      <td>-11.202700</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>96462106</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>582463</td>\n",
       "      <td>24.215500</td>\n",
       "      <td>-12.885800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>29161922</td>\n",
       "      <td>15.552727</td>\n",
       "      <td>48.516388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>17861030</td>\n",
       "      <td>-15.416700</td>\n",
       "      <td>28.283300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>14645468</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country/Region  population        Lat        Long  2020-01-22  \\\n",
       "0       Afghanistan    38041754  33.000000   65.000000         NaN   \n",
       "1           Albania     2880917  41.153300   20.168300         NaN   \n",
       "2           Algeria    43053054  28.033900    1.659600         NaN   \n",
       "3           Andorra       77142  42.506300    1.521800         NaN   \n",
       "4            Angola    31825295 -11.202700   17.873900         NaN   \n",
       "..              ...         ...        ...         ...         ...   \n",
       "182         Vietnam    96462106  16.000000  108.000000         NaN   \n",
       "183  Western Sahara      582463  24.215500  -12.885800         NaN   \n",
       "184           Yemen    29161922  15.552727   48.516388         NaN   \n",
       "185          Zambia    17861030 -15.416700   28.283300         NaN   \n",
       "186        Zimbabwe    14645468 -20.000000   30.000000         NaN   \n",
       "\n",
       "     2020-01-23  2020-01-24  2020-01-25  2020-01-26  2020-01-27  ...  \\\n",
       "0           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "1           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "2           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "3           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "4           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "..          ...         ...         ...         ...         ...  ...   \n",
       "182         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "183         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "184         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "185         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "186         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "     2020-04-20  2020-04-21  2020-04-22  2020-04-23  2020-04-24  2020-04-25  \\\n",
       "0           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4           NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "182         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "183         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "184         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "185         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "186         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     2020-04-26  2020-04-27  2020-04-28  2020-04-29  \n",
       "0           NaN         NaN         NaN         NaN  \n",
       "1           NaN         NaN         NaN         NaN  \n",
       "2           NaN         NaN         NaN         NaN  \n",
       "3           NaN         NaN         NaN         NaN  \n",
       "4           NaN         NaN         NaN         NaN  \n",
       "..          ...         ...         ...         ...  \n",
       "182         NaN         NaN         NaN         NaN  \n",
       "183         NaN         NaN         NaN         NaN  \n",
       "184         NaN         NaN         NaN         NaN  \n",
       "185         NaN         NaN         NaN         NaN  \n",
       "186         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[187 rows x 103 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R0_df = data_frames['confirmed'].copy()\n",
    "values = R0_df.loc[:, R0_df.columns[4:]].values\n",
    "Tau = 14\n",
    "\n",
    "doubling_times = np.zeros(values.shape)\n",
    "\n",
    "for i, country in enumerate(values):\n",
    "    for j, day in enumerate(country):\n",
    "        if day > 0:\n",
    "            doubling_time = np.argmax(country > day*2) - j\n",
    "            if doubling_time < 0:\n",
    "                doubling_time = -1\n",
    "            \n",
    "            doubling_times[i, j] = doubling_time\n",
    "\n",
    "K_d = np.divide(np.log(2), doubling_times, where=doubling_times>0)\n",
    "K = np.gradient(np.log(values, where=values>0), axis=1)\n",
    "R0 = np.exp(K_d * Tau)\n",
    "R0[doubling_times == -1] = np.exp(K * Tau)[doubling_times == -1]\n",
    "\n",
    "# Don't use doubling time\n",
    "R0 = np.exp(K * Tau).clip(0,10)\n",
    "R0[values < 100] = np.nan\n",
    "\n",
    "R0_df.loc[:, confirmed.columns[4:]] = R0\n",
    "R0_df.loc[(R0_df['population'] < 1000000) | (confirmed[R0_df.columns[-1]] < 10000), confirmed.columns[4:]] = np.nan\n",
    "display(R0_df)\n",
    "R0_df.describe()\n",
    "data_frames['R0'] = R0_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Add world and continents rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Continents code to name\n",
    "continents = {\n",
    "    'AF': 'Africa',\n",
    "    'AS': 'Asia',\n",
    "    'EU': 'Europe',\n",
    "    'NA': 'North America',\n",
    "    'OC': 'Oceania',\n",
    "    'SA': 'South America'\n",
    "}\n",
    "\n",
    "def country_to_continent(country):\n",
    "    \"\"\"\n",
    "    From country name get continent name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        country_code = pc.country_name_to_country_alpha2(country)\n",
    "        continent = pc.country_alpha2_to_continent_code(country_code)\n",
    "        return continents[continent]\n",
    "    except:\n",
    "        # Country unknown for pycountry -> by hand\n",
    "        if country == 'Kosovo':\n",
    "            return 'Europe'\n",
    "        elif country == 'State of Palestine':\n",
    "            return 'Asia'\n",
    "        elif country == 'Timor-Leste':\n",
    "            return 'Asia'\n",
    "        elif country == 'Vatican City':\n",
    "            return 'Europe'\n",
    "        elif country == 'Western Sahara':\n",
    "            return 'Africa'\n",
    "        else:\n",
    "            print(f\"Unkown country continent: {country}\")\n",
    "            raise ValueError\n",
    "\n",
    "            \n",
    "for key in data_frames.keys():\n",
    "    df = data_frames[key].copy()\n",
    "    \n",
    "    # Compute world aggregation\n",
    "    world = pd.Series(df.loc[0, :])\n",
    "    world['Country/Region'] = \"World\"\n",
    "    world['population'] = df['population'].sum()\n",
    "    world['Lat'] = 0\n",
    "    world['Long'] = 0\n",
    "    world.loc[world.index[4:]] = df.loc[:, df.columns[4:]].sum()\n",
    "    world = pd.DataFrame(world).T\n",
    "    \n",
    "    # Compute continents aggregation\n",
    "    df['Country/Region'] = df['Country/Region'].apply(country_to_continent)\n",
    "    \n",
    "    # Aggregation dict\n",
    "    agg_dict = {'population': 'sum',\n",
    "                'Lat': 'mean',\n",
    "                'Long': 'mean'}\n",
    "    \n",
    "    # Sum the rest of the columns\n",
    "    for column in df.columns[4:]:\n",
    "        if key == 'R0':\n",
    "            agg_dict[column] = 'mean'\n",
    "        else:\n",
    "            agg_dict[column] = 'sum'\n",
    "    \n",
    "    df = df.groupby('Country/Region').agg(agg_dict).reset_index()\n",
    "    \n",
    "    # Concat world, continents and countries\n",
    "    df = pd.concat([world, df, data_frames[key]]).reset_index(drop=True)\n",
    "    data_frames[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames['R0'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Write back data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for key in data_frames.keys():\n",
    "    data_frames[key].to_csv(f'generated/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
